---
permalink: /cv/
author_profile: false
redirect_from:
  - /resume
---

{% include base_path %}

<p>
  <a class="btn btn--large" href="{{ base_path }}/files/CV_YaxinLuo.pdf" target="_blank" rel="noopener">
    ðŸ“„ Download CV (PDF)
  </a>
</p>

Personal details
======
- Name: Yaxin Luo
- Mobile: +971 585699266 (UAE); +86 17882057622 (China)
- Email: Yaxin.Luo@mbzuai.ac.ae
- Website: https://yaxin9luo.github.io/
- Google Scholar: https://scholar.google.com/citations?user=tEaSCzYAAAAJ&hl=en

Research interests
======
My long-term goal is to develop intelligent machines capable of perceiving, understanding, and creating multimodal content (e.g., videos). Interests include multimodal
machine learning, vision foundation models, and efficient algorithms for foundation models. Recently, I am focusing on **physical aware learning** for vision models and **analysis of pretrain data of LLM**.


Education
======
* PhD in Machine Learning, MBZUAI, 2025â€“2029 (expected Dec 2029)  
  PhD Advisor: Dr. Zhiqiang Shen & Prof.Ivan Laptev
* BSc in General Engineering (specialization: Machine Learning), Technical University of Denmark, 2021â€“2025 
  Bachelor thesis advisor: Prof. Dimitrios Papadopoulos
* BSc in Mathematics, University of Edinburgh, 2020â€“2021  
  Overall grade of taken courses: UK First-Class; withdrew 19 Mar 2021 (changed major and country)

Working experience
======
* Research Assistant, MBZUAI â€” Jan 2025â€“Aug 2025
  - Analyzing LLM generalization ability on pure vision tasks using only image data  
  - Exploring reasoning in MLLMs

Publications (first author only)
======
* **ICLR 2025** â€” Î³-MoD: Exploring Mixture-of-Depth Adaptation for Multimodal Large Language Models.  
  Î³-MoD is a plug-and-play approach that replaces redundant dense layers with Mixture-of-Depth (MoD) layers to reduce computation while maintaining performance.
* **ECCV 2024** â€” APL: Anchor-based Prompt Learning for One-stage Weakly Supervised Referring Expression Comprehension.  
  Introduces an Anchor-based Prompt Encoder (APE) to fuse position, color, and category prompts into anchor features, improving weakly supervised visionâ€“language alignment with auxiliary text reconstruction and visual alignment losses; achieves SOTA on RefCOCO and ReferIt.

Other experience
======
* IEEE Cybermatics Congress 2024 â€” Conference Local Team Member (Aug 2024).  
  Acted as a conference helper and session chair of the Smart Data workshop.
* SciSec 2024 â€” Conference Helper (Aug 2024).
* Institute of Social Science Survey, Peking University â€” Summer Internship (Jul 2019â€“Sep 2019).   Internship in a public psychological healthcare project led by the Ministry of Civil Affairs, China.

Other skills
======
* Practical skills in HPC training (Slurm), DeepSpeed for LLMs; theoretical knowledge in distributed computing
* Experience from 3 course projects in embedded systems programming and circuits
* Signal processing and acoustics knowledge
* Basic knowledge in bioinformatics from DTU bachelorâ€™s biology courses

PDF preview
======
<div style="border:1px solid #e5e5e5;border-radius:8px;overflow:hidden;box-shadow:0 2px 8px rgba(0,0,0,0.04);">
  <iframe
    src="{{ base_path }}/files/CV_YaxinLuo.pdf#view=FitH"
    style="width:100%;height:820px;border:0;"
    title="CV PDF preview">
  </iframe>
</div>
