---
permalink: /
title: "Hi there! üëã I am Yaxin Luo."
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<div class="section-header">
About Me
</div>

<div class="blob-field">
<span class="sr-only">Decorative animated background</span>
<div class="about-me-content">
  <div class="intro-text">
    Hello! I am a First-Year Machine Learning PhD student at <a href="https://mbzuai.ac.ae/" class="institution-link">MBZUAI</a>, advised by <a href="https://zhiqiangshen.com/" class="advisor-link">Prof. Zhiqiang Shen</a>. I am also closely working with my friend <a href="https://xxfchen.github.io/XiaofuChen/" class="collaborator-link">Xiaofu Chen</a>.
    My research vision centers on advancing Native Multimodal Foundation Modelsthat can <strong>understand, reason, generate and agentic action across diverse modalities.</strong>  I am also interested in bridging the gap between high-performance unified intelligence and computational <strong>efficiency</strong>. Also, I care about the application side of such foundation models (Computer-Use/Device-Use Agent).
  </div>
  
  <div class="background-text">
    Previously, I earned my Bachelor‚Äôs degree from <a href="https://www.dtu.dk/english/" class="institution-link">Technical University of Denmark</a>, where I was fortunate to be supervised by <a href="https://dimipapa.github.io/" class="advisor-link">Prof. Dim P. Papadopoulos</a>. Meanwhile, I was lucky to collarating with <a href="https://scholar.google.com/citations?user=EyZqU9gAAAAJ&hl=en" class="advisor-link">Dr.Gen Luo</a> and <a href="https://scholar.google.com/citations?user=lRSD7PQAAAAJ&hl=en" class="advisor-link">Prof.Rongrong Ji</a> on efficient deep learning researches during my bachelor. 
    
    <details class="background-toggle">
      <summary>More about my earlier journey...</summary>
      <div class="toggle-content">
        I spent an intense and rewarding year at the <strong>University of Edinburgh</strong> studying pure mathematics and physics‚Äîan experience that sparked my passion for science and technology, deepened my curiosity about the unknown, I was curious and wanted to explore <strong>String Theory</strong> at that time, this one year ultimately shaped who I am today. Before Edinburgh, while enrolled in a Bio-Medicine program at the <strong>University of Queensland</strong> and preparing for the UCAT test to be addimitted into the university's medical school, I failed at the end. As I only focused on managing a high-street multi-brand boutique which was located in Brisbane's Southbank near the casino, and was far more focused on business than on study and research; that Edinburgh year changed my priorities and set me on a research path, thanks to the advice, encourage and supports of my academic personal tutor <a href="https://webhomes.maths.ed.ac.uk/~apires/" class="advisor-link">Prof.Ana Rita Pires</a> when I was at Edinburgh. <strong>Anyway, all those past experiences have made me who I am today.</strong>
      </div>
    </details>
  </div>
  
  <div class="research-interests">
    <h4>My research interests focus on:</h4>
    <ul>
      <li>
        <strong> Unified Multimodal Foundation Models </strong>: Developing native multimodal foundation models that perform unified <strong>understanding</strong>, <strong>reasoning</strong>, and <strong>generation</strong> across video, language, and speech. I aim to construct a universal interface where diverse modalities converge, enabling models to perceive complex real-world dynamics and generate coherent, high-fidelity multimodal content.
      </li>


      <li>
        <strong> Efficient Foundation Models </strong>: Tackling the efficiency challenges in scaling unified models. I explore novel architectures and mechanisms‚Äîsuch as dynamic computation allocation, efficient attention mechanisms, and token compression‚Äîto maximize performance-per-compute. The goal is to build sustainable AI systems that support long-context understanding and high-resolution generation without prohibitive computational costs.
      </li>

    </ul>
  </div>

  <div class="current-focus">
    Recently, I am focusing on Unified Multimodal Foundation Models Projects one Analysis and one on post training
</div>
</div>


<h1>News</h1>

<div class="news-item">
[2026-02-10] üöÄ <strong><a href="https://github.com/MetaAgentX/NextGen-CAPTCHAs">Next-Gen CAPTCHAs</a></strong> is now available on arXiv! A defense framework leveraging cognitive gaps against MLLM-based GUI agents.

</div>

<div class="news-item">
[2025-09-18] üöÄ <strong><a href="https://github.com/MetaAgentX/OpenCaptchaWorld">OpenCaptchaWorld</a></strong> has been accepted by NeurIPS 2025.

</div>


<div id="pub-strip-anchor"></div>

<h1>Selected Publications</h1>

<p><em>( * indicate equal contribution)</em></p>

<p>For full and up-to-date publication list, please refer to my
<a href="https://scholar.google.com/citations?user=tEaSCzYAAAAJ&hl=en">Google Scholar</a> page.</p>

<div class="pub-entry">
  <div class="pub-image">
    <img src="./images/nextgen-captchas.png">
  </div>
  <div class="pub-text">
    <strong>Next-Gen CAPTCHAs: Leveraging the Cognitive Gap for Scalable and Diverse GUI-Agent Defense</strong><br>
    <span class="venue-badge arxiv">arXiv 2026</span><br>
    Jiacheng Liu *, <strong>Yaxin Luo</strong> *, Jiacheng Cui, Xinyi Shang, Xiaohan Zhao, Zhiqiang Shen<br>
    <a href="https://arxiv.org/abs/2602.09012" class="enhanced-link paper-link">üìÑ Paper</a> <a href="https://github.com/MetaAgentX/NextGen-CAPTCHAs" class="enhanced-link code-link">üíª Code</a> <a href="https://huggingface.co/spaces/zcahjl3/NextGen-CAPTCHAs" class="enhanced-link demo-link">üöÄ Demo</a> <a href="https://greenoso.github.io/NextGen-CAPTCHAs_webpage/" class="enhanced-link demo-link">üåê Project</a>
  </div>
</div>

<div class="pub-entry">
  <div class="pub-image">
    <img src="./images/opencaptchaworld.png">
  </div>
  <div class="pub-text">
    <strong>OpenCaptchaWorld: A Comprehensive Web-based Platform for Testing and Benchmarking Multimodal LLM Agents</strong><br>
    <span class="venue-badge neurips">NeurIPS 2025</span><br>
    <strong>Yaxin Luo</strong> *, Zhaoyi Li *, Jiacheng Liu, Jiacheng Cui, Xiaohan Zhao, Zhiqiang Shen<br>
    <a href="https://arxiv.org/abs/2505.24878" class="enhanced-link paper-link">üìÑ Paper</a> <a href="https://github.com/MetaAgentX/OpenCaptchaWorld" class="enhanced-link code-link">üíª Code</a> <a href="https://huggingface.co/spaces/YaxinLuo/Open_CaptchaWorld" class="enhanced-link demo-link">üöÄ Demo</a>
  </div>
</div>

<div class="pub-entry">
  <div class="pub-image">
    <img src="./images/APL.png">
  </div>
  <div class="pub-text">
    <strong>APL: Anchor-Based Prompt Learning for One-Stage Weakly Supervised Referring Expression Comprehension</strong><br>
    <span class="venue-badge eccv">ECCV 2024</span><br>
    <strong>Yaxin Luo</strong>, Jiayi Ji, Xiaofu Chen, Yuxin Zhang, Tianhe Ren, Gen Luo<br>
    <a href="https://link.springer.com/chapter/10.1007/978-3-031-72624-8_12" class="enhanced-link paper-link">üìÑ Paper</a> <a href="https://github.com/Yaxin9Luo/APL" class="enhanced-link code-link">üíª Code</a>
  </div>
</div>

<div class="pub-entry">
  <div class="pub-image">
    <img src="./images/MoD.png">
  </div>
  <div class="pub-text">
    <strong>Œ≥-MoD: Exploring Mixture-of-Depth Adaptation for Multimodal Large Language Models</strong><br>
    <span class="venue-badge iclr">ICLR 2025</span><br>
    <strong>Yaxin Luo</strong>, Gen Luo, Jiayi Ji, Yiyi Zhou, Xiaoshuai Sun, Zhiqiang Shen, Rongrong Ji<br>
    <a href="https://arxiv.org/abs/2410.13859" class="enhanced-link paper-link">üìÑ Paper</a> <a href="https://github.com/Yaxin9Luo/gamma-MoD" class="enhanced-link code-link">üíª Code</a>
  </div>
</div>

<div class="pub-entry">
  <div class="pub-image">
    <img src="./images/DViN.png">
  </div>
  <div class="pub-text">
    <strong>DViN: Dynamic Visual Routing Network for Weakly Supervised Referring Expression Comprehension</strong><br>
    <span class="venue-badge cvpr">CVPR 2025</span><br>
    Xiaofu Chen, <strong>Yaxin Luo</strong>, Gen Luo, Jiayi Ji, Henghui Ding, Yiyi Zhou<br>
    <a href="https://openaccess.thecvf.com/content/CVPR2025/html/Chen_DViN_Dynamic_Visual_Routing_Network_for_Weakly_Supervised_Referring_Expression_CVPR_2025_paper.html" class="enhanced-link paper-link">üìÑ Paper</a> <a href="https://github.com/XxFChen/DViN" class="enhanced-link code-link">üíª Code</a>
  </div>
</div>


<style>
/* Beautiful Conference Venue Badges */
.venue-badge {
  display: inline-block;
  padding: 6px 14px;
  border-radius: 20px;
  font-size: 0.9em;
  font-weight: 700;
  text-transform: uppercase;
  letter-spacing: 0.5px;
  color: white !important;
  margin: 4px 8px 4px 0;
  box-shadow: 0 2px 8px rgba(0, 0, 0, 0.15);
  transition: all 0.3s ease;
  position: relative;
  overflow: hidden;
}

.venue-badge:before {
  content: '';
  position: absolute;
  top: 0;
  left: -100%;
  width: 100%;
  height: 100%;
  background: linear-gradient(90deg, transparent, rgba(255,255,255,0.3), transparent);
  transition: left 0.5s;
}

.venue-badge:hover {
  transform: translateY(-2px) scale(1.05);
  box-shadow: 0 6px 20px rgba(0, 0, 0, 0.25);
}

.venue-badge:hover:before {
  left: 100%;
}

/* Specific Conference Colors */
.venue-badge.cvpr {
  background: linear-gradient(135deg, #e74c3c 0%, #c0392b 100%);
}
.venue-badge.cvpr:hover { box-shadow: 0 6px 20px rgba(231, 76, 60, 0.4); }

.venue-badge.eccv {
  background: linear-gradient(135deg, #9b59b6 0%, #8e44ad 100%);
}
.venue-badge.eccv:hover { box-shadow: 0 6px 20px rgba(155, 89, 182, 0.4); }

.venue-badge.iclr {
  background: linear-gradient(135deg, #3498db 0%, #2980b9 100%);
}
.venue-badge.iclr:hover { box-shadow: 0 6px 20px rgba(52, 152, 219, 0.4); }

.venue-badge.arxiv {
  background: linear-gradient(135deg, #f39c12 0%, #e67e22 100%);
}
.venue-badge.arxiv:hover { box-shadow: 0 6px 20px rgba(243, 156, 18, 0.4); }

.venue-badge.nips,
.venue-badge.neurips {
  background: linear-gradient(135deg, #1abc9c 0%, #16a085 100%);
}
.venue-badge.nips:hover,
.venue-badge.neurips:hover { box-shadow: 0 6px 20px rgba(26, 188, 156, 0.4); }

.venue-badge.icml {
  background: linear-gradient(135deg, #34495e 0%, #2c3e50 100%);
}
.venue-badge.icml:hover { box-shadow: 0 6px 20px rgba(52, 73, 94, 0.4); }

.venue-badge.aaai {
  background: linear-gradient(135deg, #e67e22 0%, #d35400 100%);
}
.venue-badge.aaai:hover { box-shadow: 0 6px 20px rgba(230, 126, 34, 0.4); }

.venue-badge.ijcai {
  background: linear-gradient(135deg, #27ae60 0%, #229954 100%);
}
.venue-badge.ijcai:hover { box-shadow: 0 6px 20px rgba(39, 174, 96, 0.4); }

/* News item enhanced styling */
.news-item {
  padding: 15px 20px;
  margin: 12px 0;
  background: linear-gradient(135deg, rgba(52, 152, 219, 0.1) 0%, rgba(155, 89, 182, 0.1) 100%);
  border-radius: 12px;
  border-left: 4px solid #3498db;
  transition: all 0.3s ease;
}
.news-item:hover {
  transform: translateX(5px);
  box-shadow: 0 4px 15px rgba(52, 152, 219, 0.2);
  background: linear-gradient(135deg, rgba(52, 152, 219, 0.15) 0%, rgba(155, 89, 182, 0.15) 100%);
}

/* About Me section enhancement */
.section-header {
  font-size: 1.5em;
  font-weight: 700;
  color: #2c3e50;
  margin: 30px 0 15px 0;
  padding-bottom: 8px;
  border-bottom: 3px solid #3498db;
  position: relative;
}
.section-header:after {
  content: '';
  position: absolute;
  bottom: -3px;
  left: 0;
  width: 50px;
  height: 3px;
  background: linear-gradient(90deg, #3498db, #9b59b6);
}

.about-me-content {
  padding: 20px;
  margin: 15px 0;
  background: linear-gradient(135deg, rgba(52, 152, 219, 0.1) 0%, rgba(155, 89, 182, 0.1) 100%);
  border-radius: 12px;
  border-left: 4px solid #3498db;
  transition: all 0.3s ease;
  line-height: 1.6;
}
.about-me-content:hover {
  transform: translateX(3px);
  box-shadow: 0 8px 25px rgba(52, 152, 219, 0.1);
}

.about-me-content ul { margin: 15px 0; padding-left: 20px; }
.about-me-content ul li {
  margin: 8px 0; padding: 8px 0; border-radius: 8px; transition: all 0.3s ease;
}
.about-me-content ul li:hover { background: rgba(52, 152, 219, 0.1); padding-left: 10px; }

/* ‚úÖ Âè™Âä†Á≤óÔºå‰∏ç‰∏äËâ≤ */
.about-me-content strong {
  color: inherit;
  font-weight: 700;
}

/* ÂÖ®Â±ÄÈìæÊé•ÔºàAbout Âå∫ÂüüÔºâ */
.about-me-content a {
  color: #3498db;
  text-decoration: none;
  transition: all 0.3s ease;
}
.about-me-content a:hover {
  color: #9b59b6;
  text-decoration: underline;
}

/* ‚úÖ Â≠¶Ê†°/Êú∫ÊûÑÔºöÂä†Á≤óÔºå‰øùÊåÅÁªßÊâøÈ¢úËâ≤ */
.about-me-content .institution-link {
  font-weight: 700;
  color: inherit;
  text-decoration: none;
  transition: all 0.2s ease;
}
.about-me-content .institution-link:hover {
  text-decoration: underline;
}

/* ‚úÖ ‰∫∫ÂêçÔºösoft blue-green */
.about-me-content .advisor-link,
.about-me-content .collaborator-link {
  color: #5dade2;
  font-weight: 600;
  text-decoration: none;
  transition: all 0.2s ease;
}
.about-me-content .advisor-link:hover,
.about-me-content .collaborator-link:hover {
  color: #3498db;
  text-decoration: underline;
}

.about-me-content .intro-text { margin-bottom: 20px; line-height: 1.7; font-size: 1.05em; }
.about-me-content .background-text { margin-bottom: 20px; line-height: 1.6; color: #555; }

/* Toggle section for background story */
.background-toggle {
  margin-top: 12px;
  border-radius: 8px;
  overflow: hidden;
}
.background-toggle summary {
  cursor: pointer;
  font-weight: 600;
  color: #3498db;
  padding: 8px 0;
  list-style: none;
  transition: color 0.3s ease;
}
.background-toggle summary::-webkit-details-marker { display: none; }
.background-toggle summary::before {
  content: '‚ñ∏ ';
  display: inline-block;
  transition: transform 0.3s ease;
}
.background-toggle[open] summary::before {
  transform: rotate(90deg);
}
.background-toggle summary:hover { color: #9b59b6; }
.background-toggle .toggle-content {
  padding: 12px 0 4px 0;
  line-height: 1.6;
  color: #555;
  animation: fadeIn 0.3s ease;
}
@keyframes fadeIn { from { opacity: 0; transform: translateY(-5px); } to { opacity: 1; transform: translateY(0); } }

.about-me-content .current-focus {
  margin-bottom: 25px; padding: 15px;
  background: rgba(173, 216, 230, 0.3);
  border-radius: 8px; border-left: 3px solid #87ceeb; font-weight: 500;
}

.about-me-content .research-interests { margin-top: 25px; }
.about-me-content .research-interests h4 { color: #2c3e50; margin-bottom: 15px; font-size: 1.1em; font-weight: 600; }
.about-me-content .research-interests ul { margin: 0; padding-left: 0; list-style: none; }
.about-me-content .research-interests li {
  margin: 15px 0; padding: 15px;
  background: rgba(173, 216, 230, 0.2);
  border-radius: 8px; border-left: 3px solid #87ceeb;
  transition: all 0.3s ease; line-height: 1.6;
}
.about-me-content .research-interests li:hover {
  background: rgba(173, 216, 230, 0.3);
  transform: translateX(5px);
  box-shadow: 0 4px 15px rgba(135, 206, 235, 0.2);
}

.about-me-content em { color: #7f8c8d; font-style: italic; }

/* Greeting Title (unchanged visual flair) */
.greeting-title {
  display: inline-block;
  background: linear-gradient(135deg, #667eea 0%, #764ba2 50%, #f093fb 100%);
  background-size: 200% 200%;
  -webkit-background-clip: text;
  -webkit-text-fill-color: transparent;
  background-clip: text;
  animation: gradient-shift 3s ease infinite;
  font-weight: 700;
  position: relative;
  box-shadow: 0 0 20px rgba(102, 126, 234, 0.3);
  transition: all 0.3s ease;
}
.greeting-title:hover { transform: scale(1.02); box-shadow: 0 0 30px rgba(102, 126, 234, 0.5); }
.greeting-title:before {
  content: ''; position: absolute; top: -2px; left: -2px; right: -2px; bottom: -2px;
  background: linear-gradient(135deg, #667eea, #764ba2, #f093fb);
  background-size: 200% 200%; animation: gradient-shift 3s ease infinite; z-index: -1;
  border-radius: 8px; opacity: 0.3; filter: blur(4px);
}
.greeting-title:after { content: '‚ú®'; position: absolute; top: -10px; right: -15px; font-size: 0.8em; animation: sparkle 2s ease-in-out infinite; opacity: 0.8; }

.wave-emoji { display: inline-block; animation: wave 2s ease-in-out infinite; transform-origin: 70% 70%; font-size: 1.2em; }
@keyframes wave { 0%,100%{transform:rotate(0)}10%{transform:rotate(14deg)}20%{transform:rotate(-8deg)}30%{transform:rotate(14deg)}40%{transform:rotate(-4deg)}50%{transform:rotate(10deg)}60%{transform:rotate(0)} }
@keyframes rainbow-shift { 0%{background-position:0% 50%}50%{background-position:100% 50%}100%{background-position:0% 50%} }
@keyframes sparkle { 0%,100%{transform:scale(1) rotate(0); opacity:.8}50%{transform:scale(1.2) rotate(180deg); opacity:1} }

/* Publication entry layout */
.pub-entry {
  display: flex;
  align-items: flex-start;
  margin-bottom: 25px;
  padding-bottom: 25px;
  border-bottom: 1px solid #eee;
}
.pub-entry:last-child {
  border-bottom: none;
}
.pub-image {
  flex-shrink: 0;
  width: 300px;
  margin-right: 20px;
}
.pub-image img {
  width: 100%;
  border-radius: 6px;
}
.pub-text {
  flex: 1;
  line-height: 1.7;
}

/* Responsive design for badges */
@media (max-width: 768px) {
  .venue-badge { padding: 4px 10px; font-size: 0.8em; margin: 2px 4px 2px 0; }
  .pub-entry { flex-direction: column; }
  .pub-image { width: 100%; margin-right: 0; margin-bottom: 10px; }
}
@media (max-width: 480px) {
  .venue-badge { padding: 3px 8px; font-size: 0.75em; }
}
</style>
