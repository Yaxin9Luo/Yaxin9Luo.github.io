---
permalink: /
title: '<span class="greeting-title">Hi there! <span class="wave-emoji">ðŸ‘‹</span> I am <span class="name-highlight">Yaxin Luo</span></span>'
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<div class="section-header">
About Me
</div>

<div class="about-me-content">
  <div class="intro-text">
    Hello! I am a First-Year Machine Learning PhD student at <a href="https://mbzuai.ac.ae/" class="institution-link">MBZUAI</a>, advised by <a href="https://zhiqiangshen.com/" class="advisor-link">Prof. Zhiqiang Shen</a>, <a href="https://fabvio.github.io/" class="advisor-link">Dr. Fabio Pizzati</a> and <a href="https://www.di.ens.fr/~laptev/" class="advisor-link">Prof. Ivan Laptev</a>. I am also closely working with my friend <a href="https://xxfchen.github.io/XiaofuChen/" class="collaborator-link">Xiaofu Chen</a>.
  </div>
  
  <div class="background-text">
    Previously, I was a Research Assistant at MBZUAI and received my Bachelor's degree from <a href="https://www.dtu.dk/english/" class="institution-link">Technical University of Denmark</a> supervised by <a href="https://dimipapa.github.io/" class="advisor-link">Prof. Dim P. Papadopoulos</a>.
  </div>
  
  <div class="current-focus">
    Recently, I am focusing on <strong>physical aware learning</strong> for vision models and <strong>analysis of pretrain data of LLM</strong>.
  </div>
  
  <div class="research-interests">
    <h4>My research interests span:</h4>
    <ul>
      <li>
        <strong>Multimodal Foundation Model / World Model</strong>: Developing native multimodal foundation models which can perform <strong>understanding</strong>, <strong>reasoning</strong>, <strong>generation</strong> tasks from video, language, speech. These models will serve as the core intelligenceâ€”the "brain"â€”for Embodied AI, Robotics, and many other applications. <em>(My Long-Term research interest and belief)</em>
      </li>
      
      <li>
        <strong>Reinforcement Learning</strong>: I study reinforcement learning on top of pretrained and SFT-initialized models to move beyond imitationâ€”unlocking new capabilities in generative modeling and robotics, including training agents inside learned world-model environments.
      </li>
      
      <li>
        <strong>Data-centric Machine Learning</strong>: Analysis and understanding of training data, improving data quality, compressing data for training efficiency, and scalable data pipelines for curating or synthesizing high-quality training data.
      </li>
    </ul>
  </div>
</div>


News
======

<div class="news-item">
ðŸš€ <strong><a href="https://github.com/MetaAgentX/OpenCaptchaWorld">OpenCaptchaWorld</a></strong> released and expanded to double the dataset size!
</div>


Selected Publications
======
*( * indicate equal contribution)*

For full and up-to-date publication list, please refer to my [Google Scholar](https://scholar.google.com/citations?user=tEaSCzYAAAAJ&hl=en) page.

* <img src="./images/opencaptchaworld.png" width="400px" align="left" style="margin-right:10px" class="publication-image"> **OpenCaptchaWorld: AComprehensive Web-based Platform for Testing and Benchmarking Multimodal LLM Agents**
  * <span class="venue-badge arxiv">arXiv</span>
  * **Yaxin Luo** *, Zhaoyi Li *, Jiacheng Liu, Jiacheng Cui, Xiaohan Zhao, Zhiqiang Shen
  * <a href="https://arxiv.org/abs/2505.24878" class="enhanced-link paper-link">ðŸ“„ Paper</a> <a href="https://github.com/MetaAgentX/OpenCaptchaWorld" class="enhanced-link code-link">ðŸ’» Code</a> <a href="https://huggingface.co/spaces/YaxinLuo/Open_CaptchaWorld" class="enhanced-link demo-link">ðŸš€ Demo</a>

* <img src="./images/APL.png" width="400px" align="left" style="margin-right:10px" class="publication-image"> **APL: Anchor-Based Prompt Learning for One-Stage Weakly Supervised Referring Expression Comprehension**
  * <span class="venue-badge eccv">ECCV 2024</span>
  * **Yaxin Luo**,Jiayi Ji, Xiaofu Chen, Yuxin Zhang, Tianhe Ren, Gen Luo
  * <a href="https://link.springer.com/chapter/10.1007/978-3-031-72624-8_12" class="enhanced-link paper-link">ðŸ“„ Paper</a> <a href="https://github.com/Yaxin9Luo/APL" class="enhanced-link code-link">ðŸ’» Code</a>

* <img src="./images/MoD.png" width="400px" align="left" style="margin-right:10px" class="publication-image"> **Î³-MoD: Exploring Mixture-of-Depth Adaptation for Multimodal Large Language Models**
  * <span class="venue-badge iclr">ICLR 2025</span>
  * **Yaxin Luo**, Gen Luo, Jiayi Ji, Yiyi Zhou, Xiaoshuai Sun, Zhiqiang Shen, Rongrong Ji
  * <a href="https://arxiv.org/abs/2410.13859" class="enhanced-link paper-link">ðŸ“„ Paper</a> <a href="https://github.com/Yaxin9Luo/gamma-MoD" class="enhanced-link code-link">ðŸ’» Code</a>

* <img src="./images/DViN.png" width="400px" align="left" style="margin-right:10px" class="publication-image"> **DViN: Dynamic Visual Routing Network for Weakly Supervised Referring Expression Comprehension**
  * <span class="venue-badge cvpr">CVPR 2025</span>
  * Xiaofu Chen, **Yaxin Luo**, Gen Luo, Jiayi Ji, Henghui Ding, Yiyi Zhou
  * <a href="https://openaccess.thecvf.com/content/CVPR2025/html/Chen_DViN_Dynamic_Visual_Routing_Network_for_Weakly_Supervised_Referring_Expression_CVPR_2025_paper.html" class="enhanced-link paper-link">ðŸ“„ Paper</a> <a href="https://github.com/XxFChen/DViN" class="enhanced-link code-link">ðŸ’» Code</a>

<style>
/* Beautiful Conference Venue Badges */
.venue-badge {
  display: inline-block;
  padding: 6px 14px;
  border-radius: 20px;
  font-size: 0.9em;
  font-weight: 700;
  text-transform: uppercase;
  letter-spacing: 0.5px;
  color: white !important;
  margin: 4px 8px 4px 0;
  box-shadow: 0 2px 8px rgba(0, 0, 0, 0.15);
  transition: all 0.3s ease;
  position: relative;
  overflow: hidden;
}

.venue-badge:before {
  content: '';
  position: absolute;
  top: 0;
  left: -100%;
  width: 100%;
  height: 100%;
  background: linear-gradient(90deg, transparent, rgba(255,255,255,0.3), transparent);
  transition: left 0.5s;
}

.venue-badge:hover {
  transform: translateY(-2px) scale(1.05);
  box-shadow: 0 6px 20px rgba(0, 0, 0, 0.25);
}

.venue-badge:hover:before {
  left: 100%;
}

/* Specific Conference Colors */
.venue-badge.cvpr {
  background: linear-gradient(135deg, #e74c3c 0%, #c0392b 100%);
}

.venue-badge.cvpr:hover {
  box-shadow: 0 6px 20px rgba(231, 76, 60, 0.4);
}

.venue-badge.eccv {
  background: linear-gradient(135deg, #9b59b6 0%, #8e44ad 100%);
}

.venue-badge.eccv:hover {
  box-shadow: 0 6px 20px rgba(155, 89, 182, 0.4);
}

.venue-badge.iclr {
  background: linear-gradient(135deg, #3498db 0%, #2980b9 100%);
}

.venue-badge.iclr:hover {
  box-shadow: 0 6px 20px rgba(52, 152, 219, 0.4);
}

.venue-badge.arxiv {
  background: linear-gradient(135deg, #f39c12 0%, #e67e22 100%);
}

.venue-badge.arxiv:hover {
  box-shadow: 0 6px 20px rgba(243, 156, 18, 0.4);
}

.venue-badge.nips,
.venue-badge.neurips {
  background: linear-gradient(135deg, #1abc9c 0%, #16a085 100%);
}

.venue-badge.nips:hover,
.venue-badge.neurips:hover {
  box-shadow: 0 6px 20px rgba(26, 188, 156, 0.4);
}

.venue-badge.icml {
  background: linear-gradient(135deg, #34495e 0%, #2c3e50 100%);
}

.venue-badge.icml:hover {
  box-shadow: 0 6px 20px rgba(52, 73, 94, 0.4);
}

.venue-badge.aaai {
  background: linear-gradient(135deg, #e67e22 0%, #d35400 100%);
}

.venue-badge.aaai:hover {
  box-shadow: 0 6px 20px rgba(230, 126, 34, 0.4);
}

.venue-badge.ijcai {
  background: linear-gradient(135deg, #27ae60 0%, #229954 100%);
}

.venue-badge.ijcai:hover {
  box-shadow: 0 6px 20px rgba(39, 174, 96, 0.4);
}

/* News item enhanced styling */
.news-item {
  padding: 15px 20px;
  margin: 12px 0;
  background: linear-gradient(135deg, rgba(52, 152, 219, 0.1) 0%, rgba(155, 89, 182, 0.1) 100%);
  border-radius: 12px;
  border-left: 4px solid #3498db;
  transition: all 0.3s ease;
}

.news-item:hover {
  transform: translateX(5px);
  box-shadow: 0 4px 15px rgba(52, 152, 219, 0.2);
  background: linear-gradient(135deg, rgba(52, 152, 219, 0.15) 0%, rgba(155, 89, 182, 0.15) 100%);
}

/* About Me section enhancement */
.section-header {
  font-size: 1.5em;
  font-weight: 700;
  color: #2c3e50;
  margin: 30px 0 15px 0;
  padding-bottom: 8px;
  border-bottom: 3px solid #3498db;
  position: relative;
}

.section-header:after {
  content: '';
  position: absolute;
  bottom: -3px;
  left: 0;
  width: 50px;
  height: 3px;
  background: linear-gradient(90deg, #3498db, #9b59b6);
}

.about-me-content {
  padding: 20px;
  margin: 15px 0;
  background: linear-gradient(135deg, rgba(52, 152, 219, 0.1) 0%, rgba(155, 89, 182, 0.1) 100%);
  border-radius: 12px;
  border-left: 4px solid #3498db;
  transition: all 0.3s ease;
  line-height: 1.6;
}

.about-me-content:hover {
  transform: translateX(3px);
  box-shadow: 0 8px 25px rgba(52, 152, 219, 0.1);
}

.about-me-content ul {
  margin: 15px 0;
  padding-left: 20px;
}

.about-me-content ul li {
  margin: 8px 0;
  padding: 8px 0;
  border-radius: 8px;
  transition: all 0.3s ease;
}

.about-me-content ul li:hover {
  background: rgba(52, 152, 219, 0.1);
  padding-left: 10px;
}

.about-me-content strong {
  color: #3498db;
  font-weight: 600;
}

.about-me-content a {
  color: #3498db;
  text-decoration: none;
  transition: all 0.3s ease;
}

.about-me-content a:hover {
  color: #9b59b6;
  text-decoration: underline;
}

/* Enhanced About Me content structure */
.about-me-content .intro-text {
  margin-bottom: 20px;
  line-height: 1.7;
  font-size: 1.05em;
}

.about-me-content .background-text {
  margin-bottom: 20px;
  line-height: 1.6;
  color: #555;
}

.about-me-content .current-focus {
  margin-bottom: 25px;
  padding: 15px;
  background: rgba(173, 216, 230, 0.3);
  border-radius: 8px;
  border-left: 3px solid #87ceeb;
  font-weight: 500;
}

.about-me-content .research-interests {
  margin-top: 25px;
}

.about-me-content .research-interests h4 {
  color: #2c3e50;
  margin-bottom: 15px;
  font-size: 1.1em;
  font-weight: 600;
}

.about-me-content .research-interests ul {
  margin: 0;
  padding-left: 0;
  list-style: none;
}

.about-me-content .research-interests li {
  margin: 15px 0;
  padding: 15px;
  background: rgba(173, 216, 230, 0.2);
  border-radius: 8px;
  border-left: 3px solid #87ceeb;
  transition: all 0.3s ease;
  line-height: 1.6;
}

.about-me-content .research-interests li:hover {
  background: rgba(173, 216, 230, 0.3);
  transform: translateX(5px);
  box-shadow: 0 4px 15px rgba(135, 206, 235, 0.2);
}

/* Link styling */
.about-me-content .institution-link {
  color: #ff9a9e;
  font-weight: 600;
  text-decoration: none;
  transition: all 0.3s ease;
}

.about-me-content .institution-link:hover {
  color: #fad0c4;
  text-decoration: underline;
}

.about-me-content .advisor-link {
  color: #d4a5f7;
  font-weight: 500;
  text-decoration: none;
  transition: all 0.3s ease;
}

.about-me-content .advisor-link:hover {
  color: #c084fc;
  text-decoration: underline;
}

.about-me-content .collaborator-link {
  color: #7f8c8d;
  font-weight: 500;
  text-decoration: none;
  transition: all 0.3s ease;
}

.about-me-content .collaborator-link:hover {
  color: #7f8c8d;
  text-decoration: underline;
}

.about-me-content em {
  color: #7f8c8d;
  font-style: italic;
}

/* Cool Greeting Title Animations */
.greeting-title {
  display: inline-block;
  background: linear-gradient(135deg, #667eea 0%, #764ba2 50%, #f093fb 100%);
  background-size: 200% 200%;
  -webkit-background-clip: text;
  -webkit-text-fill-color: transparent;
  background-clip: text;
  animation: gradient-shift 3s ease infinite;
  font-weight: 700;
  position: relative;
}

.greeting-title:before {
  content: '';
  position: absolute;
  top: -2px;
  left: -2px;
  right: -2px;
  bottom: -2px;
  background: linear-gradient(135deg, #667eea, #764ba2, #f093fb);
  background-size: 200% 200%;
  animation: gradient-shift 3s ease infinite;
  z-index: -1;
  border-radius: 8px;
  opacity: 0.3;
  filter: blur(4px);
}

.wave-emoji {
  display: inline-block;
  animation: wave 2s ease-in-out infinite;
  transform-origin: 70% 70%;
  font-size: 1.2em;
}

@keyframes wave {
  0%, 100% { transform: rotate(0deg); }
  10% { transform: rotate(14deg); }
  20% { transform: rotate(-8deg); }
  30% { transform: rotate(14deg); }
  40% { transform: rotate(-4deg); }
  50% { transform: rotate(10deg); }
  60% { transform: rotate(0deg); }
}

.name-highlight {
  background: linear-gradient(135deg, #ff6b6b, #4ecdc4, #45b7d1, #96ceb4);
  background-size: 300% 300%;
  -webkit-background-clip: text;
  -webkit-text-fill-color: transparent;
  background-clip: text;
  animation: rainbow-shift 4s ease infinite;
  font-weight: 800;
  position: relative;
  text-shadow: 0 0 30px rgba(255, 107, 107, 0.3);
}

.name-highlight:before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: linear-gradient(135deg, #ff6b6b, #4ecdc4, #45b7d1, #96ceb4);
  background-size: 300% 300%;
  animation: rainbow-shift 4s ease infinite;
  z-index: -1;
  border-radius: 4px;
  opacity: 0.2;
  filter: blur(8px);
}

@keyframes rainbow-shift {
  0% { background-position: 0% 50%; }
  50% { background-position: 100% 50%; }
  100% { background-position: 0% 50%; }
}

/* Glowing effect for the entire title */
.greeting-title {
  box-shadow: 0 0 20px rgba(102, 126, 234, 0.3);
  transition: all 0.3s ease;
}

.greeting-title:hover {
  transform: scale(1.02);
  box-shadow: 0 0 30px rgba(102, 126, 234, 0.5);
}

/* Sparkle effect */
.greeting-title:after {
  content: 'âœ¨';
  position: absolute;
  top: -10px;
  right: -15px;
  font-size: 0.8em;
  animation: sparkle 2s ease-in-out infinite;
  opacity: 0.8;
}

@keyframes sparkle {
  0%, 100% { transform: scale(1) rotate(0deg); opacity: 0.8; }
  50% { transform: scale(1.2) rotate(180deg); opacity: 1; }
}

/* Responsive design for badges */
@media (max-width: 768px) {
  .venue-badge {
    padding: 4px 10px;
    font-size: 0.8em;
    margin: 2px 4px 2px 0;
  }
}

@media (max-width: 480px) {
  .venue-badge {
    padding: 3px 8px;
    font-size: 0.75em;
  }
}
</style>